[[chapter_12_cqrs]]
== Command-Query Responsibility Segregation (CQRS)
å‘½ä»¤-æŸ¥è¯¢èŒè´£åˆ†ç¦»ï¼ˆCQRSï¼‰

((("command-query responsibility segregation (CQRS)", id="ix_CQRS")))
((("CQRS", see="command-query responsibility segregation")))
((("queries", seealso="command-query responsibility segregation")))
In this chapter, we're going to start with a fairly uncontroversial insight:
reads (queries) and writes (commands) are different, so they
should be treated differently (or have their responsibilities segregated, if you will). Then we're going to push that insight as far
as we can. 

åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»ä¸€ä¸ªç›¸å¯¹æ²¡æœ‰äº‰è®®çš„è§‚ç‚¹å¼€å§‹ï¼š
è¯»å–ï¼ˆæŸ¥è¯¢ï¼‰å’Œå†™å…¥ï¼ˆå‘½ä»¤ï¼‰æ˜¯ä¸åŒçš„ï¼Œå› æ­¤å®ƒä»¬åº”è¯¥è¢«åŒºåˆ«å¯¹å¾…ï¼ˆæˆ–è€…è¯´ï¼Œå®ƒä»¬çš„èŒè´£åº”è¯¥è¢«åˆ†ç¦»ï¼‰ã€‚éšåï¼Œæˆ‘ä»¬å°†å°½å¯èƒ½åœ°æ·±å…¥æ¢è®¨è¿™ä¸€è§‚ç‚¹ã€‚

If you're anything like Harry, this will all seem extreme at first,
but hopefully we can make the argument that it's not _totally_ unreasonable.

å¦‚æœä½ å’Œ Harry æœ‰ç‚¹ç›¸ä¼¼ï¼Œé‚£ä¹ˆä¸€å¼€å§‹è¿™ä¸€åˆ‡å¯èƒ½çœ‹èµ·æ¥éƒ½æœ‰äº›æç«¯ï¼Œ
ä½†å¸Œæœ›æˆ‘ä»¬èƒ½å¤Ÿè¯æ˜è¿™å¹¶ä¸æ˜¯ _å®Œå…¨_ ä¸åˆç†çš„ã€‚

<<maps_chapter_11>> shows where we might end up.

<<maps_chapter_11>> å±•ç¤ºäº†æˆ‘ä»¬å¯èƒ½æœ€ç»ˆè¾¾åˆ°çš„åœ°æ–¹ã€‚

[TIP]
====
The code for this chapter is in the
chapter_12_cqrs branch https://oreil.ly/YbWGT[on [.keep-together]#GitHub#].

æœ¬ç« çš„ä»£ç ä½äº
chapter_12_cqrs åˆ†æ”¯ https://oreil.ly/YbWGT[åœ¨[.keep-together]#GitHub#]ä¸Šã€‚

----
git clone https://github.com/cosmicpython/code.git
cd code
git checkout chapter_12_cqrs
# or to code along, checkout the previous chapter:
git checkout chapter_11_external_events
----
====

First, though, why bother?

ä¸è¿‡é¦–å…ˆï¼Œä¸ºä»€ä¹ˆè¦è´¹è¿™ä¸ªåŠ²å‘¢ï¼Ÿ

[[maps_chapter_11]]
.Separating reads from writesï¼ˆå°†è¯»å–ä¸å†™å…¥åˆ†ç¦»ï¼‰
image::images/apwp_1201.png[]

=== Domain Models Are for Writing
é¢†åŸŸæ¨¡å‹æ˜¯ç”¨äºå†™å…¥çš„

((("domain model", "writing data")))
((("command-query responsibility segregation (CQRS)", "domain models for writing")))
We've spent a lot of time in this book talking about how to build software that
enforces the rules of our domain. These rules, or constraints, will be different
for every application, and they make up the interesting core of our systems.

åœ¨è¿™æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬èŠ±äº†å¤§é‡æ—¶é—´è®¨è®ºå¦‚ä½•æ„å»ºèƒ½å¤Ÿå¼ºåˆ¶æ‰§è¡Œé¢†åŸŸè§„åˆ™çš„è½¯ä»¶ã€‚è¿™äº›è§„åˆ™æˆ–çº¦æŸå¯¹äºæ¯ä¸ªåº”ç”¨ç¨‹åºè€Œè¨€éƒ½æ˜¯ä¸åŒçš„ï¼Œå®ƒä»¬æ„æˆäº†æˆ‘ä»¬ç³»ç»Ÿçš„æœ‰è¶£æ ¸å¿ƒã€‚

In this book, we've set explicit constraints like "You can't allocate more stock
than is available," as well as implicit constraints like "Each order line is
allocated to a single batch."

åœ¨è¿™æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†æ˜¾å¼çº¦æŸï¼Œä¾‹å¦‚â€œä½ ä¸èƒ½åˆ†é…è¶…è¿‡å¯ç”¨åº“å­˜çš„æ•°é‡â€ï¼Œä»¥åŠéšå¼çº¦æŸï¼Œä¾‹å¦‚â€œæ¯ä¸ªè®¢å•é¡¹åªèƒ½åˆ†é…åˆ°ä¸€ä¸ªæ‰¹æ¬¡â€ã€‚

We wrote down these rules as unit tests at the beginning of the book:

æˆ‘ä»¬åœ¨æœ¬ä¹¦å¼€ç¯‡æ—¶å°†è¿™äº›è§„åˆ™å†™æˆäº†å•å…ƒæµ‹è¯•ï¼š

[role="pagebreak-before"]
[[domain_tests]]
.Our basic domain tests (tests/unit/test_batches.py)ï¼ˆæˆ‘ä»¬çš„åŸºç¡€é¢†åŸŸæµ‹è¯•ï¼‰
====
[source,python]
----
def test_allocating_to_a_batch_reduces_the_available_quantity():
    batch = Batch("batch-001", "SMALL-TABLE", qty=20, eta=date.today())
    line = OrderLine("order-ref", "SMALL-TABLE", 2)

    batch.allocate(line)

    assert batch.available_quantity == 18

...

def test_cannot_allocate_if_available_smaller_than_required():
    small_batch, large_line = make_batch_and_line("ELEGANT-LAMP", 2, 20)
    assert small_batch.can_allocate(large_line) is False
----
====

To apply these rules properly, we needed to ensure that operations
were consistent, and so we introduced patterns like _Unit of Work_ and _Aggregate_
that help us commit small chunks of work.

ä¸ºäº†æ­£ç¡®åœ°åº”ç”¨è¿™äº›è§„åˆ™ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿æ“ä½œçš„ä¸€è‡´æ€§ï¼Œå› æ­¤æˆ‘ä»¬å¼•å…¥äº†ç±»ä¼¼ _Unit of Work_ å’Œ _Aggregate_ è¿™æ ·çš„æ¨¡å¼æ¥å¸®åŠ©æˆ‘ä»¬æäº¤å°å—çš„å·¥ä½œã€‚

To communicate changes between those small chunks, we introduced the Domain Events pattern
so we can write rules like "When stock is damaged or lost, adjust the
available quantity on the batch, and reallocate orders if necessary."

ä¸ºäº†åœ¨è¿™äº›å°å—ä¹‹é—´ä¼ é€’å˜æ›´ï¼Œæˆ‘ä»¬å¼•å…¥äº†é¢†åŸŸäº‹ä»¶ï¼ˆDomain Eventsï¼‰æ¨¡å¼ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿç¼–å†™ç±»ä¼¼è¿™æ ·çš„è§„åˆ™ï¼šâ€œå½“åº“å­˜å—æŸæˆ–ä¸¢å¤±æ—¶ï¼Œ
è°ƒæ•´æ‰¹æ¬¡ä¸­çš„å¯ç”¨æ•°é‡ï¼Œå¹¶åœ¨å¿…è¦æ—¶é‡æ–°åˆ†é…è®¢å•ã€‚â€

All of this complexity exists so we can enforce rules when we change the
state of our system. We've built a flexible set of tools for writing data.

æ‰€æœ‰è¿™äº›å¤æ‚æ€§éƒ½å­˜åœ¨çš„ç›®çš„ï¼Œæ˜¯ä¸ºäº†åœ¨æˆ‘ä»¬æ›´æ”¹ç³»ç»ŸçŠ¶æ€æ—¶èƒ½å¤Ÿå¼ºåˆ¶æ‰§è¡Œè§„åˆ™ã€‚æˆ‘ä»¬å·²ç»æ„å»ºäº†ä¸€å¥—çµæ´»çš„å·¥å…·é›†æ¥è¿›è¡Œæ•°æ®å†™å…¥ã€‚

What about reads, though?

é‚£ä¹ˆè¯»å–å‘¢ï¼Ÿ

=== Most Users Aren't Going to Buy Your Furniture
å¤§å¤šæ•°ç”¨æˆ·ä¸ä¼šè´­ä¹°ä½ çš„å®¶å…·

((("command-query responsibility segregation (CQRS)", "reads")))
At MADE.com, we have a system very like the allocation service. In a busy day, we
might process one hundred orders in an hour, and we have a big gnarly system for
allocating stock to those orders.

åœ¨ MADE.comï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªéå¸¸ç±»ä¼¼åˆ†é…æœåŠ¡çš„ç³»ç»Ÿã€‚åœ¨ç¹å¿™çš„ä¸€å¤©é‡Œï¼Œæˆ‘ä»¬å¯èƒ½æ¯å°æ—¶å¤„ç†ä¸€ç™¾ä¸ªè®¢å•ï¼Œ
å¹¶ä¸”æˆ‘ä»¬æœ‰ä¸€ä¸ªå¤æ‚çš„å¤§å‹ç³»ç»Ÿç”¨äºå°†åº“å­˜åˆ†é…ç»™è¿™äº›è®¢å•ã€‚

In that same busy day, though, we might have one hundred product views per _second_.
Each time somebody visits a product page, or a product listing page, we need
to figure out whether the product is still in stock and how long it will take
us to deliver it.

ç„¶è€Œï¼Œåœ¨åŒæ ·ç¹å¿™çš„ä¸€å¤©é‡Œï¼Œæˆ‘ä»¬æ¯ç§’å¯èƒ½ä¼šæœ‰ä¸€ç™¾æ¬¡äº§å“æµè§ˆã€‚
æ¯æ¬¡æœ‰äººè®¿é—®äº§å“é¡µé¢æˆ–äº§å“åˆ—è¡¨é¡µé¢æ—¶ï¼Œæˆ‘ä»¬éƒ½éœ€è¦ç¡®å®šäº§å“æ˜¯å¦ä»æœ‰åº“å­˜ï¼Œä»¥åŠéœ€è¦å¤šé•¿æ—¶é—´æ‰èƒ½äº¤ä»˜ã€‚

((("eventually consistent reads")))
((("consistency", "eventually consistent reads")))
The _domain_ is the same--we're concerned with batches of stock, and their
arrival date, and the amount that's still available--but the access pattern
is very different. For example, our customers won't notice if the query
is a few seconds out of date, but if our allocate service is inconsistent,
we'll make a mess of their orders. We can take advantage of this difference by
making our reads _eventually consistent_ in order to make them perform better.

_é¢†åŸŸ_ æ˜¯ç›¸åŒçš„â€”â€”æˆ‘ä»¬å…³æ³¨çš„æ˜¯åº“å­˜æ‰¹æ¬¡ã€å®ƒä»¬çš„åˆ°è¾¾æ—¥æœŸä»¥åŠä»ç„¶å¯ç”¨çš„æ•°é‡â€”â€”ä½†è®¿é—®æ¨¡å¼å´éå¸¸ä¸åŒã€‚ä¾‹å¦‚ï¼Œå¦‚æœæŸ¥è¯¢ç»“æœå­˜åœ¨å‡ ç§’çš„å»¶è¿Ÿï¼Œ
å®¢æˆ·å¯èƒ½ä¸ä¼šå¯Ÿè§‰åˆ°ï¼Œä½†å¦‚æœæˆ‘ä»¬çš„åˆ†é…æœåŠ¡å‡ºç°ä¸ä¸€è‡´ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯èƒ½æç ¸ä»–ä»¬çš„è®¢å•ã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸€å·®å¼‚ï¼Œé€šè¿‡ä½¿è¯»å–å®ç° _æœ€ç»ˆä¸€è‡´æ€§_ æ¥æé«˜æ€§èƒ½ã€‚

[role="nobreakinside less_space"]
.Is Read Consistency Truly Attainable?ï¼ˆè¯»å–ä¸€è‡´æ€§çœŸçš„å¯ä»¥å®ç°å—ï¼Ÿï¼‰
*******************************************************************************

((("command-query responsibility segregation (CQRS)", "reads", "consistency of")))
((("consistency", "attainment of read consistency")))
This idea of trading consistency against performance makes a lot of developers
[.keep-together]#nervous# at first, so let's talk quickly about that.

è¿™ç§ç”¨æ€§èƒ½äº¤æ¢ä¸€è‡´æ€§çš„æƒ³æ³•ä¸€å¼€å§‹ä¼šè®©å¾ˆå¤šå¼€å‘è€…æ„Ÿåˆ°ç´§å¼ ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬å¿«é€Ÿè®¨è®ºä¸€ä¸‹è¿™ä¸ªé—®é¢˜ã€‚

Let's imagine that our "Get Available Stock" query is 30 seconds out of date
when Bob visits the page for `ASYMMETRICAL-DRESSER`.
Meanwhile, though, Harry has already bought the last item. When we try to
allocate Bob's order, we'll get a failure, and we'll need to either cancel his
order or buy more stock and delay his delivery.

è®©æˆ‘ä»¬æƒ³è±¡ä¸€ä¸‹ï¼Œå½“ Bob è®¿é—® `ASYMMETRICAL-DRESSER` é¡µé¢æ—¶ï¼Œâ€œè·å–å¯ç”¨åº“å­˜â€çš„æŸ¥è¯¢ç»“æœå·²ç»å»¶è¿Ÿäº† 30 ç§’ã€‚ä¸æ­¤åŒæ—¶ï¼Œ
Harry å·²ç»è´­ä¹°äº†æœ€åä¸€ä»¶å•†å“ã€‚å½“æˆ‘ä»¬å°è¯•ä¸º Bob çš„è®¢å•åˆ†é…åº“å­˜æ—¶ï¼Œä¼šå‘ç”Ÿå¤±è´¥ï¼Œæˆ‘ä»¬è¦ä¹ˆéœ€è¦å–æ¶ˆä»–çš„è®¢å•ï¼Œè¦ä¹ˆé‡‡è´­æ›´å¤šåº“å­˜å¹¶å»¶è¿Ÿä»–çš„äº¤ä»˜ã€‚

People who've worked only with relational data stores get _really_ nervous
about this problem, but it's worth considering two other scenarios to gain some
perspective.

åªæ¥è§¦è¿‡å…³ç³»å‹æ•°æ®å­˜å‚¨çš„äººä¼šå¯¹è¿™ä¸ªé—®é¢˜æ„Ÿåˆ° _éå¸¸_ ç´§å¼ ï¼Œä½†å€¼å¾—é€šè¿‡è€ƒè™‘å¦å¤–ä¸¤ç§æƒ…å¢ƒæ¥è·å¾—ä¸€äº›ä¸åŒçš„è§†è§’ã€‚

First, let's imagine that Bob and Harry both visit the page at _the same
time_. Harry goes off to make coffee, and by the time he returns, Bob has
already bought the last dresser. When Harry places his order, we send it to
the allocation service, and because there's not enough stock, we have to refund
his payment or buy more stock and delay his delivery.

é¦–å…ˆï¼Œå‡è®¾ Bob å’Œ Harry åŒæ—¶è®¿é—®äº†é¡µé¢ã€‚Harry å»æ³¡å’–å•¡äº†ï¼Œå½“ä»–å›æ¥æ—¶ï¼ŒBob å·²ç»è´­ä¹°äº†æœ€åä¸€ä¸ªæŸœå­ã€‚å½“ Harry ä¸‹è®¢å•æ—¶ï¼Œ
æˆ‘ä»¬å°†å…¶å‘é€åˆ°åˆ†é…æœåŠ¡ï¼Œç„¶è€Œç”±äºåº“å­˜ä¸è¶³ï¼Œæˆ‘ä»¬ä¸å¾—ä¸é€€æ¬¾ç»™ä»–ï¼Œæˆ–è€…é‡‡è´­æ›´å¤šåº“å­˜å¹¶å»¶è¿Ÿä»–çš„äº¤ä»˜ã€‚

As soon as we render the product page, the data is already stale. This insight
is key to understanding why reads can be safely inconsistent: we'll always need
to check the current state of our system when we come to allocate, because all
distributed systems are inconsistent. As soon as you have a web server and two
customers, you have the potential for stale data.

ä¸€æ—¦æˆ‘ä»¬æ¸²æŸ“äº†äº§å“é¡µé¢ï¼Œæ•°æ®å®é™…ä¸Šå·²ç»æ˜¯è¿‡æ—¶çš„ã€‚è¿™ä¸ªè®¤çŸ¥æ˜¯ç†è§£ä¸ºä»€ä¹ˆè¯»å–å¯ä»¥å®‰å…¨åœ°ä¸ä¸€è‡´çš„å…³é”®ï¼šå½“æˆ‘ä»¬è¿›è¡Œåˆ†é…æ—¶ï¼Œ
æ€»æ˜¯éœ€è¦æ£€æŸ¥ç³»ç»Ÿçš„å½“å‰çŠ¶æ€ï¼Œå› ä¸ºæ‰€æœ‰åˆ†å¸ƒå¼ç³»ç»Ÿéƒ½æ˜¯ä¸ä¸€è‡´çš„ã€‚ä¸€æ—¦ä½ æœ‰äº†ä¸€ä¸ªç½‘é¡µæœåŠ¡å™¨å’Œä¸¤ä¸ªå®¢æˆ·ï¼Œå°±æœ‰å¯èƒ½å‡ºç°æ•°æ®è¿‡æ—¶çš„æƒ…å†µã€‚

OK, let's assume we solve that problem somehow: we magically build a totally
consistent web application where nobody ever sees stale data. This time Harry
gets to the page first and buys his dresser.

å¥½å§ï¼Œè®©æˆ‘ä»¬å‡è®¾æˆ‘ä»¬ä»¥æŸç§æ–¹å¼è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼šæˆ‘ä»¬ç¥å¥‡åœ°æ„å»ºäº†ä¸€ä¸ªå®Œå…¨ä¸€è‡´çš„ Web åº”ç”¨ç¨‹åºï¼Œç¡®ä¿æ²¡æœ‰äººä¼šçœ‹åˆ°è¿‡æ—¶çš„æ•°æ®ã€‚
è¿™æ¬¡æ˜¯ Harry å…ˆè¿›å…¥é¡µé¢å¹¶è´­ä¹°äº†ä»–çš„æŸœå­ã€‚

Unfortunately for him, when the warehouse staff tries to dispatch his furniture,
it falls off the forklift and smashes into a zillion pieces. Now what?

ä¸å¹¸çš„æ˜¯ï¼Œå½“ä»“åº“å·¥ä½œäººå‘˜å°è¯•å‘è´§æ—¶ï¼Œä»–çš„å®¶å…·ä»å‰è½¦ä¸Šæ‰ä¸‹æ¥ï¼Œæ‘”å¾—ç²‰ç¢ã€‚é‚£ä¹ˆç°åœ¨è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿ

The only options are to either call Harry and refund his order or buy more
stock and delay delivery.

å”¯ä¸€çš„é€‰æ‹©æ˜¯è¦ä¹ˆè”ç³» Harry å¹¶é€€è¿˜ä»–çš„è®¢å•ï¼Œè¦ä¹ˆé‡‡è´­æ›´å¤šåº“å­˜å¹¶æ¨è¿Ÿäº¤ä»˜ã€‚

No matter what we do, we're always going to find that our software systems are
inconsistent with reality, and so we'll always need business processes to cope
with these edge cases. It's OK to trade performance for consistency on the
read side, because stale data is essentially unavoidable.

æ— è®ºæˆ‘ä»¬åšä»€ä¹ˆï¼Œæ€»ä¼šå‘ç°æˆ‘ä»¬çš„è½¯ä»¶ç³»ç»Ÿä¸ç°å®å­˜åœ¨ä¸ä¸€è‡´ï¼Œå› æ­¤æˆ‘ä»¬å§‹ç»ˆéœ€è¦ä¸šåŠ¡æµç¨‹æ¥å¤„ç†è¿™äº›è¾¹ç¼˜æƒ…å†µã€‚
åœ¨è¯»å–æ–¹é¢ï¼Œç”¨æ€§èƒ½æ¢å–ä¸€è‡´æ€§æ˜¯å¯ä»¥æ¥å—çš„ï¼Œå› ä¸ºè¿‡æ—¶æ•°æ®æœ¬è´¨ä¸Šæ˜¯ä¸å¯é¿å…çš„ã€‚
*******************************************************************************

((("command-query responsibility segregation (CQRS)", "read side and write side")))
We can think of these requirements as forming two halves of a system:
the read side and the write side, shown in <<read_and_write_table>>.

æˆ‘ä»¬å¯ä»¥å°†è¿™äº›éœ€æ±‚çœ‹ä½œç³»ç»Ÿçš„ä¸¤ä¸ªéƒ¨åˆ†ï¼šè¯»å–ç«¯å’Œå†™å…¥ç«¯ï¼Œå¦‚ <<read_and_write_table>> æ‰€ç¤ºã€‚

For the write side, our fancy domain architectural patterns help us to evolve
our system over time, but the complexity we've built so far doesn't buy
anything for reading data. The service layer, the unit of work,  and the clever
domain model are just bloat.

å¯¹äºå†™å…¥ç«¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†é«˜çº§çš„é¢†åŸŸæ¶æ„æ¨¡å¼ï¼Œå¸®åŠ©æˆ‘ä»¬éšç€æ—¶é—´æ¼”è¿›ç³»ç»Ÿã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ç°æœ‰çš„å¤æ‚æ€§å¯¹è¯»å–æ•°æ®è€Œè¨€æ¯«æ— å¸®åŠ©ã€‚
æœåŠ¡å±‚ã€Unit of Workï¼Œä»¥åŠå·§å¦™çš„é¢†åŸŸæ¨¡å‹åœ¨è¿™é‡Œåªæ˜¯å†—ä½™ã€‚

[[read_and_write_table]]
.Read versus writeï¼ˆè¯»å–ä¸å†™å…¥å¯¹æ¯”ï¼‰
[options="header"]
|===
| | Read sideï¼ˆè¯»å–ç«¯ï¼‰ | Write sideï¼ˆå†™å…¥ç«¯ï¼‰
| Behaviorï¼ˆè¡Œä¸ºï¼‰ | Simple readï¼ˆç®€å•è¯»å–ï¼‰ | Complex business logicï¼ˆå¤æ‚çš„ä¸šåŠ¡é€»è¾‘ï¼‰
| Cacheabilityï¼ˆå¯ç¼“å­˜æ€§ï¼‰ | Highly cacheableï¼ˆé«˜åº¦å¯ç¼“å­˜ï¼‰ | Uncacheableï¼ˆä¸å¯ç¼“å­˜ï¼‰
| Consistencyï¼ˆä¸€è‡´æ€§ï¼‰ | Can be staleï¼ˆå¯ä»¥æ˜¯è¿‡æ—¶çš„ï¼‰ | Must be transactionally consistentï¼ˆå¿…é¡»å…·å¤‡äº‹åŠ¡ä¸€è‡´æ€§ï¼‰
|===


=== Post/Redirect/Get and CQS
Post/Redirect/Get ä¸ CQS

((("Post/Redirect/Get pattern")))
((("Post/Redirect/Get pattern", "command-query separation (CQS)")))
((("CQS (command-query separation)")))
((("command-query responsibility segregation (CQRS)", "Post/Redirect/Get pattern and CQS")))
If you do web development, you're probably familiar with the
Post/Redirect/Get pattern. In this technique, a web endpoint accepts an
HTTP POST and responds with a redirect to see the result. For example, we might
accept a POST to _/batches_ to create a new batch and redirect the user to
_/batches/123_ to see their newly created batch.

å¦‚æœä½ ä»äº‹ Web å¼€å‘ï¼Œä½ å¯èƒ½å¯¹ Post/Redirect/Get æ¨¡å¼éå¸¸ç†Ÿæ‚‰ã€‚åœ¨è¿™ç§æŠ€æœ¯ä¸­ï¼ŒWeb ç«¯ç‚¹æ¥æ”¶ä¸€ä¸ª HTTP POST è¯·æ±‚å¹¶é€šè¿‡é‡å®šå‘æ¥æ˜¾ç¤ºç»“æœã€‚
ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½æ¥æ”¶ä¸€ä¸ªå‘åˆ° _/batches_ çš„ POST è¯·æ±‚æ¥åˆ›å»ºä¸€ä¸ªæ–°æ‰¹æ¬¡ï¼Œå¹¶å°†ç”¨æˆ·é‡å®šå‘åˆ° _/batches/123_ æ¥æŸ¥çœ‹ä»–ä»¬æ–°åˆ›å»ºçš„æ‰¹æ¬¡ã€‚

This approach fixes the problems that arise when users refresh the results page
in their browser or try to bookmark a results page. In the case of a refresh,
it can lead to our users double-submitting data and thus buying two sofas when they
needed only one. In the case of a bookmark, our hapless customers will end up
with a broken page when they try to GET a POST endpoint.

è¿™ç§æ–¹æ³•è§£å†³äº†ç”¨æˆ·åœ¨æµè§ˆå™¨ä¸­åˆ·æ–°ç»“æœé¡µé¢æˆ–å°è¯•ä¸ºç»“æœé¡µé¢æ·»åŠ ä¹¦ç­¾æ—¶å¯èƒ½å‡ºç°çš„é—®é¢˜ã€‚åœ¨åˆ·æ–°æƒ…å†µä¸‹ï¼Œç”¨æˆ·å¯èƒ½ä¼šé‡å¤æäº¤æ•°æ®ï¼Œ
ä»è€Œå¯¼è‡´ä»–ä»¬ä¹°äº†ä¸¤å¼ æ²™å‘ï¼Œè€Œå®é™…ä¸Šåªéœ€è¦ä¸€å¼ ã€‚åœ¨ä¹¦ç­¾æƒ…å†µä¸‹ï¼Œå½“ç”¨æˆ·å°è¯• GET ä¸€ä¸ª POST ç«¯ç‚¹æ—¶ï¼Œä¼šå¯¼è‡´é¡µé¢æŸåï¼Œä»è€Œè®©é¡¾å®¢æ„Ÿåˆ°å›°æƒ‘ã€‚

Both these problems happen because we're returning data in response to a write
operation. Post/Redirect/Get sidesteps the issue by separating the read and
write phases of our operation.

è¿™ä¸¤ä¸ªé—®é¢˜éƒ½å‘ç”Ÿåœ¨æˆ‘ä»¬åœ¨å“åº”å†™æ“ä½œæ—¶è¿”å›æ•°æ®çš„æƒ…å†µä¸‹ã€‚Post/Redirect/Get é€šè¿‡å°†æ“ä½œçš„è¯»å†™é˜¶æ®µåˆ†ç¦»å¼€æ¥ï¼Œå·§å¦™åœ°é¿å¼€äº†è¿™äº›é—®é¢˜ã€‚

This technique is a simple example of command-query separation (CQS).footnote:[
We're using the terms somewhat interchangeably, but CQS is normally something you
apply to a single class or module: functions that read state should be separate from
those that modify it.  And CQRS is something you apply to your whole application:
the classes, modules, code paths and even databases that read state can be
separated from the ones that modify it.]
We follow one simple rule: functions should either modify state or answer
questions, but never both. This makes software easier to reason about: we should
always be able to ask, "Are the lights on?" without flicking the light switch.

è¿™ç§æŠ€æœ¯æ˜¯å‘½ä»¤-æŸ¥è¯¢åˆ†ç¦»ï¼ˆCQSï¼‰çš„ä¸€ä¸ªç®€å•ç¤ºä¾‹ã€‚è„šæ³¨ï¼š[æˆ‘ä»¬åœ¨è¿™é‡Œå°†ä¸€äº›æœ¯è¯­ç¨å¾®æ··ç”¨ï¼Œä½†é€šå¸¸æƒ…å†µä¸‹ï¼Œ
CQS åº”ç”¨åœ¨å•ä¸ªç±»æˆ–æ¨¡å—ä¸Šï¼šè´Ÿè´£è¯»å–çŠ¶æ€çš„å‡½æ•°åº”è¯¥ä¸ä¿®æ”¹çŠ¶æ€çš„å‡½æ•°åˆ†ç¦»ã€‚è€Œ CQRS åˆ™æ˜¯åº”ç”¨äºæ•´ä¸ªåº”ç”¨ç¨‹åºçš„ï¼š
è´Ÿè´£è¯»å–çŠ¶æ€çš„ç±»ã€æ¨¡å—ã€ä»£ç è·¯å¾„ï¼Œç”šè‡³æ•°æ®åº“ï¼Œéƒ½å¯ä»¥ä¸è´Ÿè´£ä¿®æ”¹çŠ¶æ€çš„éƒ¨åˆ†åˆ†ç¦»å¼€æ¥ã€‚]
æˆ‘ä»¬éµå¾ªä¸€ä¸ªç®€å•çš„è§„åˆ™ï¼šå‡½æ•°åº”è¯¥è¦ä¹ˆä¿®æ”¹çŠ¶æ€ï¼Œè¦ä¹ˆå›ç­”é—®é¢˜ï¼Œä½†ç»ä¸èƒ½åŒæ—¶åšè¿™ä¸¤ä»¶äº‹ã€‚è¿™ä½¿å¾—è½¯ä»¶æ›´å®¹æ˜“æ¨ç†ï¼šæˆ‘ä»¬åº”è¯¥å§‹ç»ˆèƒ½å¤Ÿé—®å‡ºâ€œç¯æ˜¯å¼€ç€çš„å—ï¼Ÿâ€
è€Œæ— éœ€è§¦ç¢°ç”µç¯å¼€å…³ã€‚

NOTE: When building APIs, we can apply the same design technique by returning a
    201 Created, or a 202 Accepted, with a Location header containing the URI
    of our new resources. What's important here isn't the status code we use
    but the logical separation of work into a write phase and a query phase.

åœ¨æ„å»º API æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è¿”å›ä¸€ä¸ª `201 Created` æˆ– `202 Accepted` çŠ¶æ€ç ï¼Œå¹¶é™„å¸¦ä¸€ä¸ªåŒ…å«æ–°èµ„æº URI çš„ Location å¤´ï¼Œ
æ¥åº”ç”¨ç›¸åŒçš„è®¾è®¡æŠ€æœ¯ã€‚è¿™é‡Œé‡è¦çš„ä¸æ˜¯æˆ‘ä»¬ä½¿ç”¨çš„çŠ¶æ€ç ï¼Œè€Œæ˜¯å°†å·¥ä½œé€»è¾‘æ¸…æ™°åœ°åˆ†ä¸ºä¸€ä¸ªå†™é˜¶æ®µå’Œä¸€ä¸ªæŸ¥è¯¢é˜¶æ®µã€‚

As you'll see, we can use the CQS principle to make our systems faster and more
scalable, but first, let's fix the CQS violation in our existing code. Ages
ago, we introduced an `allocate` endpoint that takes an order and calls our
service layer to allocate some stock. At the end of the call, we return a 200
OK and the batch ID. That's led to some ugly design flaws so that we can get
the data we need. Let's change it to return a simple OK message and instead
provide a new read-only endpoint to retrieve allocation state:

æ­£å¦‚ä½ å°†çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ CQS åŸåˆ™è®©ç³»ç»Ÿè¿è¡Œå¾—æ›´åŠ å¿«é€Ÿä¸”å…·æœ‰å¯æ‰©å±•æ€§ï¼Œä½†é¦–å…ˆï¼Œè®©æˆ‘ä»¬ä¿®å¤ç°æœ‰ä»£ç ä¸­è¿å CQS çš„æƒ…å†µã€‚å¾ˆä¹…ä»¥å‰ï¼Œ
æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ª `allocate` ç«¯ç‚¹ï¼Œå®ƒæ¥æ”¶ä¸€ä¸ªè®¢å•å¹¶è°ƒç”¨æœåŠ¡å±‚æ¥åˆ†é…åº“å­˜ã€‚åœ¨è°ƒç”¨ç»“æŸæ—¶ï¼Œæˆ‘ä»¬è¿”å›ä¸€ä¸ª 200 OK å’Œæ‰¹æ¬¡ IDã€‚ä¸ºäº†è·å–æ‰€éœ€çš„æ•°æ®ï¼Œ
è¿™ç§åšæ³•å¯¼è‡´äº†ä¸€äº›éš¾çœ‹çš„è®¾è®¡ç¼ºé™·ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°†å…¶æ”¹ä¸ºä»…è¿”å›ä¸€ä¸ªç®€å•çš„ OK æ¶ˆæ¯ï¼Œå¹¶æ–°å¢ä¸€ä¸ªåªè¯»ç«¯ç‚¹æ¥è·å–åˆ†é…çŠ¶æ€ï¼š


[[api_test_does_get_after_post]]
.API test does a GET after the POST (tests/e2e/test_api.py)ï¼ˆAPI æµ‹è¯•åœ¨ POST ä¹‹åæ‰§è¡Œ GETï¼‰
====
[source,python]
----
@pytest.mark.usefixtures("postgres_db")
@pytest.mark.usefixtures("restart_api")
def test_happy_path_returns_202_and_batch_is_allocated():
    orderid = random_orderid()
    sku, othersku = random_sku(), random_sku("other")
    earlybatch = random_batchref(1)
    laterbatch = random_batchref(2)
    otherbatch = random_batchref(3)
    api_client.post_to_add_batch(laterbatch, sku, 100, "2011-01-02")
    api_client.post_to_add_batch(earlybatch, sku, 100, "2011-01-01")
    api_client.post_to_add_batch(otherbatch, othersku, 100, None)

    r = api_client.post_to_allocate(orderid, sku, qty=3)
    assert r.status_code == 202

    r = api_client.get_allocation(orderid)
    assert r.ok
    assert r.json() == [
        {"sku": sku, "batchref": earlybatch},
    ]


@pytest.mark.usefixtures("postgres_db")
@pytest.mark.usefixtures("restart_api")
def test_unhappy_path_returns_400_and_error_message():
    unknown_sku, orderid = random_sku(), random_orderid()
    r = api_client.post_to_allocate(
        orderid, unknown_sku, qty=20, expect_success=False
    )
    assert r.status_code == 400
    assert r.json()["message"] == f"Invalid sku {unknown_sku}"

    r = api_client.get_allocation(orderid)
    assert r.status_code == 404
----
====

((("views", "read-only")))
((("Flask framework", "endpoint for viewing allocations")))
OK, what might the Flask app look like?

å¥½çš„ï¼Œé‚£ä¹ˆ Flask åº”ç”¨ç¨‹åºå¯èƒ½ä¼šåƒè¿™æ ·ï¼š


[[flask_app_calls_view]]
.Endpoint for viewing allocations (src/allocation/entrypoints/flask_app.py)ï¼ˆæŸ¥çœ‹åˆ†é…çš„ç«¯ç‚¹ï¼‰
====
[source,python]
----
from allocation import views
...

@app.route("/allocations/<orderid>", methods=["GET"])
def allocations_view_endpoint(orderid):
    uow = unit_of_work.SqlAlchemyUnitOfWork()
    result = views.allocations(orderid, uow)  #<1>
    if not result:
        return "not found", 404
    return jsonify(result), 200
----
====

<1> All right, a _views.py_, fair enough; we can keep read-only stuff in there,
    and it'll be a real _views.py_, not like Django's, something that knows how
    to build read-only views of our data...
å¥½çš„ï¼Œä¸€ä¸ª _views.py_ æ–‡ä»¶ï¼Œå¬èµ·æ¥å¾ˆåˆç†ï¼›æˆ‘ä»¬å¯ä»¥æŠŠåªè¯»çš„å†…å®¹æ”¾åœ¨é‚£é‡Œï¼Œå¹¶ä¸”å®ƒå°†æ˜¯ä¸€ä¸ªçœŸæ­£çš„ _views.py_ æ–‡ä»¶ï¼Œ
ä¸åƒ Django çš„é‚£ç§ï¼Œè€Œæ˜¯ä¸€äº›äº†è§£å¦‚ä½•æ„å»ºæˆ‘ä»¬æ•°æ®åªè¯»è§†å›¾çš„ä¸œè¥¿...

[[hold-on-ch12]]
=== Hold On to Your Lunch, Folks
æŠ“ç¨³äº†ï¼Œå„ä½ï¼

((("SQL", "raw SQL in views")))
((("repositories", "adding list method to existing repository object")))
((("command-query responsibility segregation (CQRS)", "building read-only views into our data")))
Hmm, so we can probably just add a list method to our existing repository
object:

å—¯ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯èƒ½åªéœ€è¦åœ¨ç°æœ‰çš„ä»“å‚¨å¯¹è±¡ä¸­æ·»åŠ ä¸€ä¸ªåˆ—è¡¨æ–¹æ³•ï¼š


[[views_dot_py]]
.Views do...raw SQL? (src/allocation/views.py)ï¼ˆè§†å›¾ä¸­æ‰§è¡Œ...åŸç”Ÿ SQLï¼Ÿï¼‰
====
[source,python]
[role="non-head"]
----
from allocation.service_layer import unit_of_work


def allocations(orderid: str, uow: unit_of_work.SqlAlchemyUnitOfWork):
    with uow:
        results = uow.session.execute(
            """
            SELECT ol.sku, b.reference
            FROM allocations AS a
            JOIN batches AS b ON a.batch_id = b.id
            JOIN order_lines AS ol ON a.orderline_id = ol.id
            WHERE ol.orderid = :orderid
            """,
            dict(orderid=orderid),
        )
    return [{"sku": sku, "batchref": batchref} for sku, batchref in results]
----
====


_Excuse me?  Raw SQL?_

_ä¸æ˜¯å“¥ä»¬å„¿ï¼Ÿ åŸç”ŸSQLï¼Ÿ_

If you're anything like Harry encountering this pattern for the first time,
you'll be wondering what on earth Bob has been smoking. We're hand-rolling our
own SQL now, and converting database rows directly to dicts? After all the
effort we put into building a nice domain model? And what about the Repository
pattern? Isn't that meant to be our abstraction around the database? Why don't
we reuse that?

å¦‚æœä½ å’Œç¬¬ä¸€æ¬¡é‡åˆ°è¿™ç§æ¨¡å¼çš„ Harry ä¸€æ ·ï¼Œä½ å¯èƒ½ä¼šç–‘æƒ‘ Bob åˆ°åº•åœ¨æŠ½ä»€ä¹ˆä¸œè¥¿ã€‚æˆ‘ä»¬ç°åœ¨ç«Ÿç„¶å¼€å§‹æ‰‹å†™ SQLï¼Œè¿˜ç›´æ¥å°†æ•°æ®åº“è¡Œè½¬æ¢æˆå­—å…¸ï¼Ÿ
é‚£æˆ‘ä»¬ä¹‹å‰èŠ±äº†é‚£ä¹ˆå¤šç²¾åŠ›æ„å»ºä¸€ä¸ªä¼˜é›…çš„é¢†åŸŸæ¨¡å‹ç®—ä»€ä¹ˆï¼Ÿè¿˜æœ‰ä»“å‚¨æ¨¡å¼å‘¢ï¼Ÿå®ƒä¸æ­£æ˜¯ç”¨æ¥ä½œä¸ºæ•°æ®åº“çš„æŠ½è±¡å±‚å—ï¼Ÿä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸é‡å¤åˆ©ç”¨å®ƒå‘¢ï¼Ÿ

Well, let's explore that seemingly simpler alternative first, and see what it
looks like in practice.

é‚£ä¹ˆï¼Œæˆ‘ä»¬å…ˆæ¥æ¢ç´¢ä¸€ä¸‹é‚£ä¸ªçœ‹ä¼¼æ›´ç®€å•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œçœ‹çœ‹å®ƒåœ¨å®é™…ä¸­çš„è¡¨ç°æ˜¯ä»€ä¹ˆæ ·çš„ã€‚


We'll still keep our view in a separate _views.py_ module; enforcing a clear
distinction between reads and writes in your application is still a good idea.
We apply command-query separation, and it's easy to see which code modifies
state (the event handlers) and which code just retrieves read-only state (the views).

æˆ‘ä»¬ä»ç„¶ä¼šå°†è§†å›¾ä¿å­˜åœ¨ä¸€ä¸ªå•ç‹¬çš„ _views.py_ æ¨¡å—ä¸­ï¼›åœ¨åº”ç”¨ä¸­å¼ºåˆ¶åŒºåˆ†è¯»æ“ä½œå’Œå†™æ“ä½œä¾ç„¶æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚æˆ‘ä»¬åº”ç”¨äº†å‘½ä»¤-æŸ¥è¯¢åˆ†ç¦»åŸåˆ™ï¼Œ
è¿™ä½¿å¾—å¾ˆå®¹æ˜“åŒºåˆ†å“ªäº›ä»£ç æ˜¯ä¿®æ”¹çŠ¶æ€çš„ï¼ˆäº‹ä»¶å¤„ç†å™¨ï¼‰ï¼Œå“ªäº›ä»£ç åªæ˜¯ç”¨æ¥æ£€ç´¢åªè¯»çŠ¶æ€çš„ï¼ˆè§†å›¾ï¼‰ã€‚

TIP: Splitting out your read-only views from your state-modifying
    command and event handlers is probably a good idea, even if you
    don't want to go to full-blown CQRS.
å³ä½¿ä½ ä¸æ‰“ç®—å®Œå…¨é‡‡ç”¨ CQRSï¼Œå°†åªè¯»è§†å›¾ä¸ä¿®æ”¹çŠ¶æ€çš„å‘½ä»¤å’Œäº‹ä»¶å¤„ç†å™¨åˆ†ç¦»å¼€æ¥å¯èƒ½ä¹Ÿæ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚


=== Testing CQRS Views
æµ‹è¯• CQRS è§†å›¾

((("views", "testing CQRS views")))
((("testing", "integration test for CQRS view")))
((("command-query responsibility segregation (CQRS)", "testing views")))
Before we get into exploring various options, let's talk about testing.
Whichever approaches you decide to go for, you're probably going to need
at least one integration test.  Something like this:

åœ¨æˆ‘ä»¬å¼€å§‹æ¢ç´¢å„ç§é€‰é¡¹ä¹‹å‰ï¼Œå…ˆæ¥è°ˆè°ˆæµ‹è¯•ã€‚ä¸ç®¡ä½ å†³å®šé‡‡ç”¨å“ªç§æ–¹æ³•ï¼Œä½ å¯èƒ½è‡³å°‘éƒ½éœ€è¦ä¸€ä¸ªé›†æˆæµ‹è¯•ã€‚å®ƒå¯èƒ½ä¼šåƒè¿™æ ·ï¼š


[[integration_testing_views]]
.An integration test for a view (tests/integration/test_views.py)ï¼ˆè§†å›¾çš„é›†æˆæµ‹è¯•ï¼‰
====
[source,python]
----
def test_allocations_view(sqlite_session_factory):
    uow = unit_of_work.SqlAlchemyUnitOfWork(sqlite_session_factory)
    messagebus.handle(commands.CreateBatch("sku1batch", "sku1", 50, None), uow)  #<1>
    messagebus.handle(commands.CreateBatch("sku2batch", "sku2", 50, today), uow)
    messagebus.handle(commands.Allocate("order1", "sku1", 20), uow)
    messagebus.handle(commands.Allocate("order1", "sku2", 20), uow)
    # add a spurious batch and order to make sure we're getting the right ones
    messagebus.handle(commands.CreateBatch("sku1batch-later", "sku1", 50, today), uow)
    messagebus.handle(commands.Allocate("otherorder", "sku1", 30), uow)
    messagebus.handle(commands.Allocate("otherorder", "sku2", 10), uow)

    assert views.allocations("order1", uow) == [
        {"sku": "sku1", "batchref": "sku1batch"},
        {"sku": "sku2", "batchref": "sku2batch"},
    ]
----
====

<1> We do the setup for the integration test by using the public entrypoint to
    our application, the message bus. That keeps our tests decoupled from
    any implementation/infrastructure details about how things get stored.
æˆ‘ä»¬é€šè¿‡ä½¿ç”¨åº”ç”¨ç¨‹åºçš„å…¬å…±å…¥å£ç‚¹ï¼ˆæ¶ˆæ¯æ€»çº¿ï¼‰æ¥ä¸ºé›†æˆæµ‹è¯•è¿›è¡Œè®¾ç½®ã€‚è¿™æ ·å¯ä»¥è®©æˆ‘ä»¬çš„æµ‹è¯•ä¸å­˜å‚¨æ–¹æ³•çš„ä»»ä½•å®ç°/åŸºç¡€è®¾æ–½ç»†èŠ‚è§£è€¦ã€‚

////
IDEA: sidebar on testing views.  some old content follows.

Before you dismiss the need to use integration tests as just another
anti-feather in the anti-cap of this total antipattern, it's worth thinking
through the alternatives.

- If you're going via the `Products` repository, then you'll need integration
  tests for any new query methods you add.

- If you're going via the ORM, you'll still need integration tests

- And if you decide to build a read-only `BatchRepository`, ignoring
  the purists that tell you you're not allowed to have a Repository for
  a non-Aggregate model class, call it `BatchDAL` if you want, in any case,
  you'll still need integration tests for _that_.

So the choice is about whether or not you want a layer of abstraction between
your permanent storage and the logic of your read-only views.

* If the views are relatively simple (all the logic in our case is in filtering
  down to the right batch references), then adding another layer doesn't seem
  worth it.

* If your views do more complex calculations, or need to invoke some business
  rules to decide what to display... If, in short, you find yourself writing a
  lot of integration tests for a single view, then it may be worth building
  that intermediary layer, so that you can test the SQL and the
  display/calculation/view logic separately

IDEA: some example code showing a DAL layer in front of some read-only view
code with more complex business logic.

////



=== "Obvious" Alternative 1: Using the Existing Repository
â€œæ˜¾è€Œæ˜“è§â€çš„æ›¿ä»£æ–¹æ¡ˆ 1ï¼šä½¿ç”¨ç°æœ‰çš„ä»“å‚¨

((("views", "simple view that uses the repository")))
((("command-query responsibility segregation (CQRS)", "simple view using existing repository")))
((("repositories", "simple view using existing repository")))
How about adding a helper method to our `products` repository?

åœ¨æˆ‘ä»¬çš„ `products` ä»“å‚¨ä¸­æ·»åŠ ä¸€ä¸ªè¾…åŠ©æ–¹æ³•æ€ä¹ˆæ ·ï¼Ÿ


[[view_using_repo]]
.A simple view that uses the repository (src/allocation/views.py)ï¼ˆä½¿ç”¨ä»“å‚¨çš„ç®€å•è§†å›¾ï¼‰
====
[source,python]
[role="skip"]
----
from allocation import unit_of_work

def allocations(orderid: str, uow: unit_of_work.AbstractUnitOfWork):
    with uow:
        products = uow.products.for_order(orderid=orderid)  #<1>
        batches = [b for p in products for b in p.batches]  #<2>
        return [
            {'sku': b.sku, 'batchref': b.reference}
            for b in batches
            if orderid in b.orderids  #<3>
        ]
----
====

<1> Our repository returns `Product` objects, and we need to find all the
    products for the SKUs in a given order, so we'll build a new helper method
    called `.for_order()` on the repository.
æˆ‘ä»¬çš„ä»“å‚¨è¿”å› `Product` å¯¹è±¡ï¼Œè€Œæˆ‘ä»¬éœ€è¦æ ¹æ®ç»™å®šè®¢å•ä¸­çš„ SKU æ‰¾åˆ°æ‰€æœ‰çš„äº§å“ï¼Œå› æ­¤æˆ‘ä»¬å°†åœ¨ä»“å‚¨ä¸­æ„å»ºä¸€ä¸ªåä¸º `.for_order()` çš„æ–°è¾…åŠ©æ–¹æ³•ã€‚

<2> Now we have products but we actually want batch references, so we
    get all the possible batches with a list comprehension.
ç°åœ¨æˆ‘ä»¬æœ‰äº†äº§å“ï¼Œä½†å®é™…ä¸Šæˆ‘ä»¬éœ€è¦çš„æ˜¯æ‰¹æ¬¡å¼•ç”¨ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼è·å–æ‰€æœ‰å¯èƒ½çš„æ‰¹æ¬¡ã€‚

<3> We filter _again_ to get just the batches for our specific
    order. That, in turn, relies on our `Batch` objects being able to tell us
    which order IDs it has allocated.
æˆ‘ä»¬ _å†æ¬¡_ è¿›è¡Œè¿‡æ»¤ï¼Œä»¥ä»…è·å–é’ˆå¯¹ç‰¹å®šè®¢å•çš„æ‰¹æ¬¡ã€‚è¿™åˆä¾èµ–äºæˆ‘ä»¬çš„ `Batch` å¯¹è±¡èƒ½å¤Ÿå‘Šè¯‰æˆ‘ä»¬å®ƒå·²åˆ†é…äº†å“ªäº›è®¢å• IDã€‚

We implement that last using a `.orderid` property:

æˆ‘ä»¬é€šè¿‡å®ç°ä¸€ä¸ª `.orderid` å±æ€§æ¥å®Œæˆæœ€åä¸€æ­¥ï¼š


[[orderids_on_batch]]
.An arguably unnecessary property on our model (src/allocation/domain/model.py)ï¼ˆä¸€ä¸ªåœ¨æˆ‘ä»¬çš„æ¨¡å‹ä¸­å¯ä»¥è¯´æ˜¯å¤šä½™çš„å±æ€§ï¼‰
====
[source,python]
[role="skip"]
----
class Batch:
    ...

    @property
    def orderids(self):
        return {l.orderid for l in self._allocations}
----
====

You can start to see that reusing our existing repository and domain model classes
is not as straightforward as you might have assumed.  We've had to add new helper
methods to both, and we're doing a bunch of looping and filtering in Python, which
is work that would be done much more efficiently by the database.

ä½ å¯ä»¥å¼€å§‹å‘ç°ï¼Œé‡ç”¨æˆ‘ä»¬ç°æœ‰çš„ä»“å‚¨å’Œé¢†åŸŸæ¨¡å‹ç±»å¹¶ä¸åƒä½ å¯èƒ½æƒ³è±¡çš„é‚£æ ·ç®€å•ã€‚æˆ‘ä»¬éœ€è¦åœ¨ä¸¤è€…ä¸­éƒ½æ·»åŠ æ–°çš„è¾…åŠ©æ–¹æ³•ï¼Œ
è€Œä¸”æˆ‘ä»¬åœ¨ _Python_ ä¸­è¿›è¡Œäº†ä¸€å †å¾ªç¯å’Œè¿‡æ»¤ï¼Œè€Œè¿™äº›å·¥ä½œå®é™…ä¸Šç”±æ•°æ®åº“æ¥å®Œæˆä¼šé«˜æ•ˆå¾—å¤šã€‚

So yes, on the plus side we're reusing our existing abstractions, but on the
downside, it all feels quite clunky.

æ‰€ä»¥æ˜¯çš„ï¼Œå¥½çš„ä¸€é¢æ˜¯æˆ‘ä»¬é‡ç”¨äº†ç°æœ‰çš„æŠ½è±¡ï¼Œä½†åçš„ä¸€é¢æ˜¯ï¼Œè¿™ä¸€åˆ‡çœ‹èµ·æ¥éƒ½ç›¸å½“ç¬¨æ‹™ã€‚


=== Your Domain Model Is Not Optimized for Read Operations
ä½ çš„é¢†åŸŸæ¨¡å‹å¹¶æœªé’ˆå¯¹è¯»æ“ä½œè¿›è¡Œä¼˜åŒ–

((("domain model", "not optimized for read operations")))
((("command-query responsibility segregation (CQRS)", "domain model not optimized for read operations")))
What we're seeing here are the effects of having a domain model that
is designed primarily for write operations, while our requirements for
reads are often conceptually quite different.

æˆ‘ä»¬åœ¨è¿™é‡Œçœ‹åˆ°çš„æ˜¯ä¸€ä¸ªä¸»è¦ä¸ºå†™æ“ä½œè®¾è®¡çš„é¢†åŸŸæ¨¡å‹æ‰€å¸¦æ¥çš„å½±å“ï¼Œè€Œæˆ‘ä»¬å¯¹è¯»æ“ä½œçš„éœ€æ±‚åœ¨æ¦‚å¿µä¸Šé€šå¸¸æ˜¯å®Œå…¨ä¸åŒçš„ã€‚

This is the chin-stroking-architect's justification for CQRS.  As we've said before,
a domain model is not a data model--we're trying to capture the way the
business works: workflow, rules around state changes, messages exchanged;
concerns about how the system reacts to external events and user input.
_Most of this stuff is totally irrelevant for read-only operations_.

è¿™å°±æ˜¯é‚£äº›æ²‰æ€çš„æ¶æ„å¸ˆä»¬ä¸º CQRS æå‡ºçš„ç†ç”±ã€‚æ­£å¦‚æˆ‘ä»¬ä¹‹å‰æ‰€è¯´ï¼Œé¢†åŸŸæ¨¡å‹å¹¶ä¸æ˜¯æ•°æ®æ¨¡å‹â€”â€”æˆ‘ä»¬è¯•å›¾æ•æ‰ä¸šåŠ¡çš„è¿ä½œæ–¹å¼ï¼šå·¥ä½œæµç¨‹ã€
çŠ¶æ€å˜åŒ–çš„è§„åˆ™ã€äº¤æ¢çš„æ¶ˆæ¯ï¼›ä»¥åŠç³»ç»Ÿå¦‚ä½•å¯¹å¤–éƒ¨äº‹ä»¶å’Œç”¨æˆ·è¾“å…¥ä½œå‡ºååº”çš„å…³æ³¨ç‚¹ã€‚_è¿™äº›å†…å®¹ä¸­çš„å¤§éƒ¨åˆ†ä¸åªè¯»æ“ä½œå®Œå…¨æ— å…³_ã€‚

TIP: This justification for CQRS is related to the justification for the Domain
    Model pattern. If you're building a simple CRUD app, reads and writes are
    going to be closely related, so you don't need a domain model or CQRS. But
    the more complex your domain, the more likely you are to need both.
è¿™ç§å¯¹ CQRS çš„è§£é‡Šä¸é¢†åŸŸæ¨¡å‹æ¨¡å¼çš„è§£é‡Šæ˜¯ç›¸å…³çš„ã€‚å¦‚æœä½ åœ¨æ„å»ºä¸€ä¸ªç®€å•çš„ CRUD åº”ç”¨ï¼Œè¯»æ“ä½œå’Œå†™æ“ä½œä¼šå¯†åˆ‡ç›¸å…³ï¼Œå› æ­¤ä½ ä¸éœ€è¦é¢†åŸŸæ¨¡å‹æˆ– CQRSã€‚
ä½†ä½ çš„é¢†åŸŸè¶Šå¤æ‚ï¼Œå°±è¶Šæœ‰å¯èƒ½åŒæ—¶éœ€è¦å®ƒä»¬ã€‚

To make a facile point, your domain classes will have multiple methods for
modifying state, and you won't need any of them for read-only operations.

ç®€å•æ¥è¯´ï¼Œä½ çš„é¢†åŸŸç±»ä¼šæœ‰å¤šä¸ªç”¨æ¥ä¿®æ”¹çŠ¶æ€çš„æ–¹æ³•ï¼Œè€Œåœ¨åªè¯»æ“ä½œä¸­ï¼Œä½ å°†å®Œå…¨ä¸éœ€è¦è¿™äº›æ–¹æ³•ã€‚

As the complexity of your domain model grows, you will find yourself making
more and more choices about how to structure that model, which make it more and
more awkward to use for read operations.

éšç€é¢†åŸŸæ¨¡å‹å¤æ‚æ€§çš„å¢åŠ ï¼Œä½ ä¼šå‘ç°è‡ªå·±éœ€è¦åšå‡ºè¶Šæ¥è¶Šå¤šå…³äºå¦‚ä½•æ„å»ºè¯¥æ¨¡å‹çš„é€‰æ‹©ï¼Œè€Œè¿™äº›é€‰æ‹©ä¼šè®©å®ƒåœ¨è¿›è¡Œè¯»æ“ä½œæ—¶æ˜¾å¾—è¶Šæ¥è¶Šåˆ«æ‰­ã€‚


===  "Obvious" Alternative 2: Using the ORM
â€œæ˜¾è€Œæ˜“è§â€çš„æ›¿ä»£æ–¹æ¡ˆ 2ï¼šä½¿ç”¨ ORM

((("command-query responsibility segregation (CQRS)", "view that uses the ORM")))
((("views", "simple view that uses the ORM")))
((("object-relational mappers (ORMs)", "simple view using the ORM")))
You may be thinking, OK, if our repository is clunky, and working with
`Products` is clunky, then I can at least  use my ORM and work with `Batches`.
That's what it's for!

ä½ å¯èƒ½ä¼šæƒ³ï¼Œå¥½å§ï¼Œå¦‚æœæˆ‘ä»¬çš„ä»“å‚¨å¾ˆç¬¨æ‹™ï¼Œæ“ä½œ `Products` ä¹Ÿå¾ˆç¬¨æ‹™ï¼Œé‚£ä¹ˆè‡³å°‘æˆ‘å¯ä»¥ä½¿ç”¨æˆ‘çš„ ORMï¼Œå¹¶æ“ä½œ `Batches`ã€‚è¿™ä¸æ­£æ˜¯å®ƒçš„ç”¨é€”å—ï¼

[[view_using_orm]]
.A simple view that uses the ORM (src/allocation/views.py)ï¼ˆä½¿ç”¨ ORM çš„ç®€å•è§†å›¾ï¼‰
====
[source,python]
[role="skip"]
----
from allocation import unit_of_work, model

def allocations(orderid: str, uow: unit_of_work.AbstractUnitOfWork):
    with uow:
        batches = uow.session.query(model.Batch).join(
            model.OrderLine, model.Batch._allocations
        ).filter(
            model.OrderLine.orderid == orderid
        )
        return [
            {"sku": b.sku, "batchref": b.batchref}
            for b in batches
        ]
----
====

But is that _actually_ any easier to write or understand than the raw SQL
version from the code example in <<hold-on-ch12>>? It may not look too bad up there, but we
can tell you it took several attempts, and plenty of digging through the
SQLAlchemy docs. SQL is just SQL.

ä½†è¿™çœŸçš„æ¯” <<hold-on-ch12>> ä¸­ä»£ç ç¤ºä¾‹ä¸­çš„åŸç”Ÿ SQL æ›´å®¹æ˜“ç¼–å†™æˆ–ç†è§£å—ï¼Ÿä»è¡¨é¢ä¸Šçœ‹ï¼Œå®ƒå¯èƒ½ä¸ç®—å¤ªç³Ÿï¼Œä½†æˆ‘ä»¬å¯ä»¥å‘Šè¯‰ä½ ï¼Œ
è¿™å®é™…ä¸Šç»å†äº†å¤šæ¬¡å°è¯•ï¼Œå¹¶ä¸”èŠ±äº†å¤§é‡æ—¶é—´æŸ¥é˜… SQLAlchemy çš„æ–‡æ¡£ã€‚è€Œ SQL å°±åªæ˜¯ SQLã€‚

////
IDEA (hynek)
this seems like a PERFECT opportunity to talk about SQLAlchemy Core API. If you
have questions, pls talk to me. But jumping from ORM directly to raw SQL is
baby/bathwater.
////

But the ORM can also expose us to performance problems.

ä½†æ˜¯ï¼ŒORM ä¹Ÿå¯èƒ½ä¼šè®©æˆ‘ä»¬é¢ä¸´æ€§èƒ½é—®é¢˜ã€‚


=== SELECT N+1 and Other Performance Considerations
SELECT N+1 å’Œå…¶ä»–æ€§èƒ½è€ƒè™‘å› ç´ 


((("SELECT N+1")))
((("object-relational mappers (ORMs)", "SELECT N+1 performance problem")))
((("command-query responsibility segregation (CQRS)", "SELECT N+1 and other performance problems")))
    The so-called https://oreil.ly/OkBOS[`SELECT N+1`]
    problem is a common performance problem with ORMs: when retrieving a list of
    objects, your ORM will often perform an initial query to, say, get all the IDs
    of the objects it needs, and then issue individual queries for each object to
    retrieve their attributes. This is especially likely if there are any foreign-key relationships on your objects.

æ‰€è°“çš„ https://oreil.ly/OkBOS[`SELECT N+1`] é—®é¢˜æ˜¯ ORM ä¸­ä¸€ä¸ªå¸¸è§çš„æ€§èƒ½é—®é¢˜ï¼šåœ¨æ£€ç´¢å¯¹è±¡åˆ—è¡¨æ—¶ï¼ŒORM é€šå¸¸ä¼šæ‰§è¡Œä¸€ä¸ªåˆå§‹æŸ¥è¯¢ï¼Œ
æ¯”å¦‚è·å–å®ƒéœ€è¦çš„æ‰€æœ‰å¯¹è±¡çš„ IDï¼Œç„¶åä¸ºæ¯ä¸ªå¯¹è±¡å•ç‹¬å‘èµ·æŸ¥è¯¢ä»¥æ£€ç´¢å…¶å±æ€§ã€‚å¦‚æœä½ çš„å¯¹è±¡ä¸Šå­˜åœ¨ä»»ä½•å¤–é”®å…³ç³»ï¼Œè¿™ç§æƒ…å†µå°¤å…¶å¯èƒ½å‘ç”Ÿã€‚

NOTE: In all fairness, we should say that SQLAlchemy is quite good at avoiding
    the `SELECT N+1` problem. It doesn't display it in the preceding example, and
    you can request https://oreil.ly/XKDDm[eager loading]
    explicitly to avoid it when dealing with joined objects.
    ((("eager loading")))
    ((("SQLAlchemy", "SELECT N+1 problem and")))
å¹³å¿ƒè€Œè®ºï¼Œæˆ‘ä»¬éœ€è¦è¯´æ˜ SQLAlchemy åœ¨é¿å… `SELECT N+1` é—®é¢˜æ–¹é¢åšå¾—ç›¸å½“ä¸é”™ã€‚åœ¨å‰é¢çš„ç¤ºä¾‹ä¸­å¹¶æœªå‡ºç°è¯¥é—®é¢˜ï¼Œ
å¹¶ä¸”ä½ å¯ä»¥é€šè¿‡æ˜¾å¼è¯·æ±‚ https://oreil.ly/XKDDm[é¢„åŠ è½½ï¼ˆeager loadingï¼‰] æ¥åœ¨å¤„ç†å…³è”å¯¹è±¡æ—¶é¿å…è¯¥é—®é¢˜ã€‚

Beyond `SELECT N+1`, you may have other reasons for wanting to decouple the
way you persist state changes from the way that you retrieve current state.
A set of fully normalized relational tables is a good way to make sure that
write operations never cause data corruption. But retrieving data using lots
of joins can be slow. It's common in such cases to add some denormalized views,
build read replicas, or even add caching layers.

é™¤äº† `SELECT N+1` ä¹‹å¤–ï¼Œä½ å¯èƒ½è¿˜æœ‰å…¶ä»–åŸå› æƒ³è¦å°†æŒä¹…åŒ–çŠ¶æ€å˜åŒ–çš„æ–¹å¼ä¸æ£€ç´¢å½“å‰çŠ¶æ€çš„æ–¹å¼è§£è€¦ã€‚
ä¸€ç»„å®Œå…¨è§„èŒƒåŒ–çš„å…³ç³»è¡¨æ˜¯ä¸€ç§ç¡®ä¿å†™æ“ä½œä¸ä¼šå¯¼è‡´æ•°æ®æŸåçš„å¥½æ–¹æ³•ã€‚ç„¶è€Œï¼Œä½¿ç”¨å¤§é‡è¿æ¥ï¼ˆjoinsï¼‰æ¥æ£€ç´¢æ•°æ®å¯èƒ½ä¼šå¾ˆæ…¢ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ
å¸¸è§çš„åšæ³•æ˜¯æ·»åŠ ä¸€äº›åè§„èŒƒåŒ–çš„è§†å›¾ã€æ„å»ºåªè¯»å‰¯æœ¬ï¼Œç”šè‡³æ·»åŠ ç¼“å­˜å±‚ã€‚


=== Time to Completely Jump the Shark
æ˜¯æ—¶å€™å½»åº•æŒ‘æˆ˜æé™äº†

((("views", "keeping totally separate, denormalized datastore for view model")))
((("command-query responsibility segregation (CQRS)", "denormalized copy of your data optimized for read operations")))
On that note: have we convinced you that our raw SQL version isn't so weird as
it first seemed? Perhaps we were exaggerating for effect? Just you wait.

è¯´åˆ°è¿™é‡Œï¼šæˆ‘ä»¬æœ‰æ²¡æœ‰è®©ä½ ç›¸ä¿¡ï¼Œå…¶å®æˆ‘ä»¬çš„åŸç”Ÿ SQL ç‰ˆæœ¬å¹¶æ²¡æœ‰æœ€åˆçœ‹ä¸Šå»é‚£ä¹ˆå¥‡æ€ªï¼Ÿä¹Ÿè®¸æˆ‘ä»¬ä¸ºäº†æ•ˆæœæœ‰äº›å¤¸å¼ ï¼Ÿæ‹­ç›®ä»¥å¾…å§ã€‚

So, reasonable or not, that hardcoded SQL query is pretty ugly, right? What if
we made it nicer...

é‚£ä¹ˆï¼Œä¸ç®¡å®ƒæ˜¯å¦åˆç†ï¼Œé‚£æ®µç¡¬ç¼–ç çš„ SQL æŸ¥è¯¢çœ‹èµ·æ¥ç¡®å®å¾ˆéš¾çœ‹ï¼Œå¯¹å§ï¼Ÿå¦‚æœæˆ‘ä»¬è®©å®ƒæ›´ä¼˜é›…ä¸€äº›å‘¢...

[[much_nicer_query]]
.A much nicer query (src/allocation/views.py)ï¼ˆä¸€ä¸ªæ›´å¥½çœ‹çš„æŸ¥è¯¢ï¼‰
====
[source,python]
----
def allocations(orderid: str, uow: unit_of_work.SqlAlchemyUnitOfWork):
    with uow:
        results = uow.session.execute(
            """
            SELECT sku, batchref FROM allocations_view WHERE orderid = :orderid
            """,
            dict(orderid=orderid),
        )
        ...
----
====

...by _keeping a totally separate, denormalized data store for our view model_?

...é€šè¿‡ _ä¸ºæˆ‘ä»¬çš„è§†å›¾æ¨¡å‹ä¿ç•™ä¸€ä¸ªå®Œå…¨ç‹¬ç«‹çš„åè§„èŒƒåŒ–æ•°æ®å­˜å‚¨_ï¼Ÿ

[[new_table]]
.Hee hee hee, no foreign keys, just strings, YOLO (src/allocation/adapters/orm.py)ï¼ˆhie hie hieï¼Œä¸ç”¨å¤–é”®ï¼Œç›´æ¥å­˜å­—ç¬¦ä¸²ï¼Œç®¡å®ƒå‘¢ğŸ˜†ï¼‰
====
[source,python]
----
allocations_view = Table(
    "allocations_view",
    metadata,
    Column("orderid", String(255)),
    Column("sku", String(255)),
    Column("batchref", String(255)),
)
----
====


OK, nicer-looking SQL queries wouldn't be a justification for anything really,
but building a denormalized copy of your data that's optimized for read operations
isn't uncommon, once you've reached the limits of what you can do with indexes.

å¥½çš„ï¼Œæ›´ä¼˜é›…çš„ SQL æŸ¥è¯¢å¹¶ä¸è¶³ä»¥ä½œä¸ºæŸç§è§£å†³æ–¹æ¡ˆçš„ç†ç”±ï¼Œä½†ä¸€æ—¦ä½ è¾¾åˆ°äº†ç´¢å¼•ä¼˜åŒ–çš„æé™ï¼Œ
ä¸ºä½ çš„æ•°æ®æ„å»ºä¸€ä¸ªä¸“é—¨é’ˆå¯¹è¯»æ“ä½œä¼˜åŒ–çš„åè§„èŒƒåŒ–å‰¯æœ¬å…¶å®å¹¶ä¸ç½•è§ã€‚

Even with well-tuned indexes, a relational database uses a lot of CPU to perform
joins. The fastest queries will always be pass:[<code>SELECT * from <em>mytable</em> WHERE <em>key</em> = :<em>value</em></code>].

å³ä½¿ä½¿ç”¨äº†ç²¾å¿ƒè°ƒæ•´çš„ç´¢å¼•ï¼Œå…³ç³»å‹æ•°æ®åº“åœ¨æ‰§è¡Œè¿æ¥ï¼ˆjoinsï¼‰æ—¶ä»ç„¶ä¼šæ¶ˆè€—å¤§é‡ CPUã€‚
æœ€å¿«çš„æŸ¥è¯¢æ°¸è¿œæ˜¯ç±»ä¼¼äºï¼špass:[<code>SELECT * from <em>mytable</em> WHERE <em>key</em> = :<em>value</em></code>] çš„æŸ¥è¯¢ã€‚

((("SELECT * FROM WHERE queries")))
More than raw speed, though, this approach buys us scale. When we're writing
data to a relational database, we need to make sure that we get a lock over the
rows we're changing so we don't run into consistency problems.

ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å¸¦æ¥çš„ä¸ä»…ä»…æ˜¯åŸå§‹é€Ÿåº¦ä¸Šçš„æå‡ï¼Œè¿˜èƒ½ä¸ºæˆ‘ä»¬æä¾›æ‰©å±•æ€§ã€‚å½“æˆ‘ä»¬å‘å…³ç³»å‹æ•°æ®åº“å†™å…¥æ•°æ®æ—¶ï¼Œ
éœ€è¦ç¡®ä¿å¯¹æ­£åœ¨ä¿®æ”¹çš„è¡ŒåŠ é”ï¼Œä»¥é¿å…ä¸€è‡´æ€§é—®é¢˜ã€‚

If multiple clients are changing data at the same time, we'll have weird race
conditions. When we're _reading_ data, though, there's no limit to the number
of clients that can concurrently execute. For this reason, read-only stores can
be horizontally scaled out.

å¦‚æœå¤šä¸ªå®¢æˆ·ç«¯åŒæ—¶ä¿®æ”¹æ•°æ®ï¼Œå°±ä¼šå‡ºç°å¥‡æ€ªçš„ç«äº‰æ¡ä»¶ã€‚ç„¶è€Œï¼Œå½“æˆ‘ä»¬ _è¯»å–_ æ•°æ®æ—¶ï¼Œå¹¶å‘æ‰§è¡Œçš„å®¢æˆ·ç«¯æ•°é‡æ˜¯æ²¡æœ‰é™åˆ¶çš„ã€‚
å› æ­¤ï¼Œåªè¯»å­˜å‚¨å¯ä»¥è¿›è¡Œæ¨ªå‘æ‰©å±•ã€‚

TIP: Because read replicas can be inconsistent, there's no limit to how many we
    can have. If you're struggling to scale a system with a complex data store,
    ask whether you could build a simpler read model.
ç”±äºåªè¯»å‰¯æœ¬å¯èƒ½ä¼šå­˜åœ¨ä¸ä¸€è‡´æ€§ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥æ‹¥æœ‰ä»»æ„æ•°é‡çš„å‰¯æœ¬ã€‚å¦‚æœä½ åœ¨å°è¯•ä¸ºä¸€ä¸ªå¤æ‚çš„æ•°æ®å­˜å‚¨ç³»ç»Ÿæ‰©å±•æ—¶é‡åˆ°å›°éš¾ï¼Œ
å¯ä»¥è€ƒè™‘æ˜¯å¦èƒ½å¤Ÿæ„å»ºä¸€ä¸ªæ›´ç®€å•çš„è¯»æ¨¡å‹ã€‚

((("views", "updating read model table using event handler")))
((("command-query responsibility segregation (CQRS)", "updating read model table using event handler")))
((("event handlers", "updating read model table using")))
Keeping the read model up to date is the challenge!  Database views
(materialized or otherwise) and triggers are a common solution, but that limits
you to your database. We'd like to show you how to reuse our event-driven
architecture instead.

è®©è¯»æ¨¡å‹ä¿æŒæœ€æ–°æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼æ•°æ®åº“è§†å›¾ï¼ˆæ— è®ºæ˜¯ç‰©åŒ–è§†å›¾è¿˜æ˜¯å…¶ä»–å½¢å¼ï¼‰ä»¥åŠè§¦å‘å™¨æ˜¯å¸¸è§çš„è§£å†³æ–¹æ¡ˆï¼Œä½†è¿™ä¼šå°†ä½ é™åˆ¶åœ¨æ•°æ®åº“çš„è¾¹ç•Œå†…ã€‚
æˆ‘ä»¬å¸Œæœ›å‘ä½ å±•ç¤ºå¦‚ä½•æ”¹ç”¨æˆ‘ä»¬çš„äº‹ä»¶é©±åŠ¨æ¶æ„æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚


==== Updating a Read Model Table Using an Event Handler
ä½¿ç”¨äº‹ä»¶å¤„ç†å™¨æ›´æ–°è¯»æ¨¡å‹è¡¨

We add a second handler to the `Allocated` event:

æˆ‘ä»¬ä¸º `Allocated` äº‹ä»¶æ·»åŠ äº†ç¬¬äºŒä¸ªå¤„ç†å™¨ï¼š

[[new_handler_for_allocated]]
.Allocated event gets a new handler (src/allocation/service_layer/messagebus.py)ï¼ˆåˆ†é…äº‹ä»¶æ–°å¢äº†ä¸€ä¸ªå¤„ç†å™¨ï¼‰
====
[source,python]
----
EVENT_HANDLERS = {
    events.Allocated: [
        handlers.publish_allocated_event,
        handlers.add_allocation_to_read_model,
    ],
----
====

Here's what our update-view-model code looks like:

ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„æ›´æ–°è§†å›¾æ¨¡å‹ä»£ç çš„æ ·å­ï¼š


[[update_view_model_1]]
.Update on allocation (src/allocation/service_layer/handlers.py)ï¼ˆæ›´æ–°åˆ†é…ä¿¡æ¯ï¼‰
====
[source,python]
----

def add_allocation_to_read_model(
    event: events.Allocated,
    uow: unit_of_work.SqlAlchemyUnitOfWork,
):
    with uow:
        uow.session.execute(
            """
            INSERT INTO allocations_view (orderid, sku, batchref)
            VALUES (:orderid, :sku, :batchref)
            """,
            dict(orderid=event.orderid, sku=event.sku, batchref=event.batchref),
        )
        uow.commit()
----
====

Believe it or not, that will pretty much work!  _And it will work
against the exact same integration tests as the rest of our options._

ä¿¡ä¸ä¿¡ç”±ä½ ï¼Œè¿™æ ·å‡ ä¹å°±å¯ä»¥å·¥ä½œäº†ï¼_è€Œä¸”å®ƒå¯ä»¥é€šè¿‡ä¸æˆ‘ä»¬å…¶ä»–é€‰é¡¹å®Œå…¨ç›¸åŒçš„é›†æˆæµ‹è¯•ã€‚_

OK, you'll also need to handle `Deallocated`:

å¥½çš„ï¼Œä½ è¿˜éœ€è¦å¤„ç† `Deallocated`ï¼š


[[handle_deallocated_too]]
.A second listener for read model updatesï¼ˆç”¨äºè¯»æ¨¡å‹æ›´æ–°çš„ç¬¬äºŒä¸ªç›‘å¬å™¨ï¼‰
====
[source,python]
[role="skip"]
----
events.Deallocated: [
    handlers.remove_allocation_from_read_model,
    handlers.reallocate
],

...

def remove_allocation_from_read_model(
    event: events.Deallocated,
    uow: unit_of_work.SqlAlchemyUnitOfWork,
):
    with uow:
        uow.session.execute(
            """
            DELETE FROM allocations_view
            WHERE orderid = :orderid AND sku = :sku
            ...
----
====


<<read_model_sequence_diagram>> shows the flow across the two requests.

<<read_model_sequence_diagram>> å±•ç¤ºäº†åœ¨è¿™ä¸¤ä¸ªè¯·æ±‚ä¹‹é—´çš„æµç¨‹ã€‚

[[read_model_sequence_diagram]]
.Sequence diagram for read modelï¼ˆè¯»æ¨¡å‹çš„åºåˆ—å›¾ï¼‰
image::images/apwp_1202.png[]
[role="image-source"]
----
[plantuml, apwp_1202, config=plantuml.cfg]
@startuml
scale 4
!pragma teoz true

actor User order 1
boundary Flask order 2
participant MessageBus order 3
participant "Domain Model" as Domain order 4
participant View order 9
database DB order 10

User -> Flask: POST to allocate Endpoint
Flask -> MessageBus : Allocate Command

group UoW/transaction 1
    MessageBus -> Domain : allocate()
    MessageBus -> DB: commit write model
end

group UoW/transaction 2
    Domain -> MessageBus : raise Allocated event(s)
    MessageBus -> DB : update view model
end

Flask -> User: 202 OK

User -> Flask: GET allocations endpoint
Flask -> View: get allocations
View -> DB: SELECT on view model
DB -> View: some allocations
& View -> Flask: some allocations
& Flask -> User: some allocations

@enduml
----

In <<read_model_sequence_diagram>>, you can see two
transactions in the POST/write operation, one to update the write model and one
to update the read model, which the GET/read operation can use.

åœ¨ <<read_model_sequence_diagram>> ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ° POST/å†™æ“ä½œä¸­æœ‰ä¸¤ä¸ªäº‹åŠ¡ï¼Œä¸€ä¸ªç”¨äºæ›´æ–°å†™æ¨¡å‹ï¼Œ
å¦ä¸€ä¸ªç”¨äºæ›´æ–°è¯»æ¨¡å‹ï¼Œè€Œ GET/è¯»æ“ä½œå¯ä»¥ä½¿ç”¨è¯¥è¯»æ¨¡å‹çš„æ•°æ®ã€‚

[role="nobreakinside less_space"]
.Rebuilding from Scratchï¼ˆä»å¤´å¼€å§‹é‡å»ºï¼‰
*******************************************************************************

((("command-query responsibility segregation (CQRS)", "rebuilding view model from scratch")))
((("views", "rebuilding view model from scratch")))
"What happens when it breaks?" should be the first question we ask as engineers.

â€œå½“å®ƒå‡ºé—®é¢˜æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿâ€åº”è¯¥æ˜¯æˆ‘ä»¬ä½œä¸ºå·¥ç¨‹å¸ˆé¦–å…ˆè¦é—®çš„é—®é¢˜ã€‚

How do we deal with a view model that hasn't been updated because of a bug or
temporary outage? Well, this is just another case where events and commands can
fail independently.

æˆ‘ä»¬è¯¥å¦‚ä½•å¤„ç†å› ä¸ºé”™è¯¯æˆ–æš‚æ—¶æ€§ä¸­æ–­è€Œæœªæ›´æ–°çš„è§†å›¾æ¨¡å‹å‘¢ï¼Ÿå…¶å®ï¼Œè¿™æ­£æ˜¯å¦ä¸€ç§äº‹ä»¶å’Œå‘½ä»¤å¯ä»¥ç‹¬ç«‹å¤±è´¥çš„æƒ…å†µã€‚

If we _never_ updated the view model, and the `ASYMMETRICAL-DRESSER` was forever in
stock, that would be annoying for customers, but the `allocate` service would
still fail, and we'd take action to fix the problem.

å¦‚æœæˆ‘ä»¬ _ä»æœª_ æ›´æ–°è§†å›¾æ¨¡å‹ï¼Œè€Œ `ASYMMETRICAL-DRESSER` æ°¸è¿œæ˜¾ç¤ºæœ‰åº“å­˜ï¼Œè¿™å¯¹å®¢æˆ·æ¥è¯´ä¼šå¾ˆçƒ¦äººï¼Œ
ä½† `allocate` æœåŠ¡ä»ç„¶ä¼šå¤±è´¥ï¼Œæˆ‘ä»¬å°±ä¼šé‡‡å–è¡ŒåŠ¨æ¥ä¿®å¤è¿™ä¸ªé—®é¢˜ã€‚

Rebuilding a view model is easy, though. Since we're using a service layer to
update our view model, we can write a tool that does the following:

ä¸è¿‡ï¼Œé‡å»ºè§†å›¾æ¨¡å‹æ˜¯å¾ˆå®¹æ˜“çš„ã€‚ç”±äºæˆ‘ä»¬ä½¿ç”¨æœåŠ¡å±‚æ¥æ›´æ–°è§†å›¾æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ç¼–å†™ä¸€ä¸ªå·¥å…·æ¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

* Queries the current state of the write side to work out what's currently
  allocated
æŸ¥è¯¢å†™ä¾§çš„å½“å‰çŠ¶æ€ï¼Œä»¥ç¡®å®šå½“å‰å·²ç»åˆ†é…äº†ä»€ä¹ˆã€‚
* Calls the `add_allocation_to_read_model` handler for each allocated item
ä¸ºæ¯ä¸ªå·²åˆ†é…çš„é¡¹ç›®è°ƒç”¨ `add_allocation_to_read_model` å¤„ç†å™¨ã€‚

We can use this technique to create entirely new read models from historical
data.

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ç§æŠ€æœ¯ä»å†å²æ•°æ®ä¸­åˆ›å»ºå…¨æ–°çš„è¯»æ¨¡å‹ã€‚
*******************************************************************************

=== Changing Our Read Model Implementation Is Easy
æ›´æ”¹æˆ‘ä»¬çš„è¯»æ¨¡å‹å®ç°éå¸¸ç®€å•

((("command-query responsibility segregation (CQRS)", "changing read model implementation to use Redis")))
((("Redis, changing read model implementation to use")))
Let's see the flexibility that our event-driven model buys us in action,
by seeing what happens if we ever decide we want to implement a read model by
using a totally separate storage engine, Redis.

è®©æˆ‘ä»¬é€šè¿‡å®é™…æ“ä½œæ¥çœ‹çœ‹äº‹ä»¶é©±åŠ¨æ¨¡å‹ä¸ºæˆ‘ä»¬å¸¦æ¥çš„çµæ´»æ€§ï¼Œå¦‚æœæˆ‘ä»¬å†³å®šè¦é€šè¿‡ä½¿ç”¨ä¸€ä¸ªå®Œå…¨ç‹¬ç«‹çš„å­˜å‚¨å¼•æ“ï¼ˆå¦‚ Redisï¼‰æ¥å®ç°è¯»æ¨¡å‹ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆã€‚

Just watch:

è¯·çœ‹ï¼š


[[redis_readmodel_handlers]]
.Handlers update a Redis read model (src/allocation/service_layer/handlers.py)ï¼ˆå¤„ç†å™¨æ›´æ–° Redis è¯»æ¨¡å‹ï¼‰
====
[source,python]
[role="non-head"]
----
def add_allocation_to_read_model(event: events.Allocated, _):
    redis_eventpublisher.update_readmodel(event.orderid, event.sku, event.batchref)


def remove_allocation_from_read_model(event: events.Deallocated, _):
    redis_eventpublisher.update_readmodel(event.orderid, event.sku, None)
----
====

The helpers in our Redis module are one-liners:

æˆ‘ä»¬ Redis æ¨¡å—ä¸­çš„è¾…åŠ©æ–¹æ³•éƒ½æ˜¯ä¸€è¡Œä»£ç ï¼š


[[redis_readmodel_client]]
.Redis read model read and update (src/allocation/adapters/redis_eventpublisher.py)
====
[source,python]
[role="non-head"]
----
def update_readmodel(orderid, sku, batchref):
    r.hset(orderid, sku, batchref)


def get_readmodel(orderid):
    return r.hgetall(orderid)
----
====

(Maybe the name __redis_eventpublisher.py__ is a misnomer now, but you get the idea.)

ï¼ˆä¹Ÿè®¸ç°åœ¨æ–‡ä»¶å __redis_eventpublisher.py__ æœ‰äº›åä¸å‰¯å®äº†ï¼Œä½†ä½ æ˜ç™½å®ƒçš„æ„ä¹‰ã€‚ï¼‰

And the view itself changes very slightly to adapt to its new backend:

è§†å›¾æœ¬èº«ä¹Ÿç¨ä½œè°ƒæ•´ä»¥é€‚åº”å®ƒçš„æ–°åç«¯ï¼š

[[redis_readmodel_view]]
.View adapted to Redis (src/allocation/views.py)ï¼ˆé€‚é… Redis çš„è§†å›¾ï¼‰
====
[source,python]
[role="non-head"]
----
def allocations(orderid: str):
    batches = redis_eventpublisher.get_readmodel(orderid)
    return [
        {"batchref": b.decode(), "sku": s.decode()}
        for s, b in batches.items()
    ]
----
====



And the _exact same_ integration tests that we had before still pass,
because they are written at a level of abstraction that's decoupled from the
implementation: setup puts messages on the message bus, and the assertions
are against our view.

ä¹‹å‰çš„ _å®Œå…¨ç›¸åŒçš„_ é›†æˆæµ‹è¯•ä»ç„¶å¯ä»¥é€šè¿‡ï¼Œå› ä¸ºå®ƒä»¬æ˜¯ä»¥ä¸€ä¸ªä¸å®ç°è§£è€¦çš„æŠ½è±¡å±‚çº§ç¼–å†™çš„ï¼šè®¾ç½®é˜¶æ®µå°†æ¶ˆæ¯æ”¾åˆ°æ¶ˆæ¯æ€»çº¿ä¸­ï¼Œè€Œæ–­è¨€é’ˆå¯¹çš„æ˜¯æˆ‘ä»¬çš„è§†å›¾ã€‚

TIP: Event handlers are a great way to manage updates to a read model,
    if you decide you need one.  They also make it easy to change the
    implementation of that read model at a later date.
    ((("event handlers", "managing updates to read model")))
å¦‚æœä½ å†³å®šéœ€è¦ä¸€ä¸ªè¯»æ¨¡å‹ï¼Œäº‹ä»¶å¤„ç†å™¨æ˜¯ç®¡ç†è¯»æ¨¡å‹æ›´æ–°çš„ç»ä½³æ–¹å¼ã€‚åŒæ—¶ï¼Œå®ƒä»¬ä¹Ÿä½¿å¾—æ—¥åæ›´æ”¹è¯»æ¨¡å‹çš„å®ç°å˜å¾—éå¸¸å®¹æ˜“ã€‚

.Exercise for the Readerï¼ˆè¯»è€…ç»ƒä¹ ï¼‰
**********************************************************************
Implement another view, this time to show the allocation for a single
order line.

å®ç°å¦ä¸€ä¸ªè§†å›¾ï¼Œè¿™æ¬¡æ˜¯ç”¨äºæ˜¾ç¤ºå•ä¸ªè®¢å•è¡Œçš„åˆ†é…æƒ…å†µã€‚

Here the trade-offs between using hardcoded SQL versus going via a repository
should be much more blurry.  Try a few versions (maybe including going
to Redis), and see which you prefer.

åœ¨è¿™é‡Œï¼Œä½¿ç”¨ç¡¬ç¼–ç  SQL ä¸é€šè¿‡ä»“å‚¨çš„æƒè¡¡å¯èƒ½ä¼šæ˜¾å¾—æ›´åŠ æ¨¡ç³Šã€‚å°è¯•å®ç°å‡ ä¸ªç‰ˆæœ¬ï¼ˆä¹Ÿè®¸åŒ…æ‹¬ä½¿ç”¨ Redis çš„ç‰ˆæœ¬ï¼‰ï¼Œçœ‹çœ‹ä½ æ›´å–œæ¬¢å“ªä¸€ç§ã€‚
**********************************************************************


=== Wrap-Up
æ€»ç»“

((("views", "trade-offs for view model options")))
((("command-query responsibility segregation (CQRS)", "trade-offs for view model options")))
<<view_model_tradeoffs>> proposes some pros and cons for each of our options.

<<view_model_tradeoffs>> æå‡ºäº†æˆ‘ä»¬æ¯ç§é€‰é¡¹çš„ä¼˜ç¼ºç‚¹ã€‚

((("command-query responsibility segregation (CQRS)", "full-blown CQRS versus simpler options")))
As it happens, the allocation service at MADE.com does use "full-blown" CQRS,
with a read model stored in Redis, and even a second layer of cache provided
by Varnish. But its use cases are quite a bit different from what
we've shown here. For the kind of allocation service we're building, it seems
unlikely that you'd need to use a separate read model and event handlers for
updating it.

å®é™…ä¸Šï¼ŒMADE.com çš„åˆ†é…æœåŠ¡ç¡®å®ä½¿ç”¨äº†â€œå®Œå…¨å®ç°â€çš„ CQRSï¼Œè¯»æ¨¡å‹å­˜å‚¨åœ¨ Redis ä¸­ï¼Œå¹¶ä¸”ç”šè‡³æœ‰ä¸€å±‚ç”± Varnish æä¾›çš„ç¼“å­˜ã€‚
ä½†å®ƒçš„ç”¨ä¾‹ä¸æˆ‘ä»¬åœ¨è¿™é‡Œå±•ç¤ºçš„æƒ…å†µæœ‰ç›¸å½“å¤§çš„ä¸åŒã€‚å¯¹äºæˆ‘ä»¬æ­£åœ¨æ„å»ºçš„è¿™ç§åˆ†é…æœåŠ¡è€Œè¨€ï¼Œä¼¼ä¹ä¸å¤ªå¯èƒ½éœ€è¦ä½¿ç”¨å•ç‹¬çš„è¯»æ¨¡å‹å’Œäº‹ä»¶å¤„ç†å™¨æ¥å¯¹å…¶è¿›è¡Œæ›´æ–°ã€‚

But as your domain model becomes richer and more complex, a simplified read
model become ever more compelling.

ä½†æ˜¯ï¼Œéšç€ä½ çš„é¢†åŸŸæ¨¡å‹å˜å¾—æ›´åŠ ä¸°å¯Œå’Œå¤æ‚ï¼Œä¸€ä¸ªç®€åŒ–çš„è¯»æ¨¡å‹å°†å˜å¾—æ„ˆå‘å…·æœ‰å¸å¼•åŠ›ã€‚

[[view_model_tradeoffs]]
[options="header"]
.Trade-offs of various view model optionsï¼ˆå„ç§è§†å›¾æ¨¡å‹é€‰é¡¹çš„æƒè¡¡åˆ©å¼Šï¼‰
|===
| Optionï¼ˆé€‰é¡¹ï¼‰ | Prosï¼ˆä¼˜ç‚¹ï¼‰ | Consï¼ˆç¼ºç‚¹ï¼‰

| Just use repositoriesï¼ˆä½¿ç”¨ä»“å‚¨ï¼‰
| Simple, consistent approach.ï¼ˆç®€å•ä¸”ä¸€è‡´çš„æ–¹æ³•ã€‚ï¼‰
| Expect performance issues with complex query patterns.ï¼ˆåœ¨å¤æ‚çš„æŸ¥è¯¢æ¨¡å¼ä¸‹å¯èƒ½ä¼šé‡åˆ°æ€§èƒ½é—®é¢˜ã€‚ï¼‰

| Use custom queries with your ORMï¼ˆä½¿ç”¨å¸¦è‡ªå®šä¹‰æŸ¥è¯¢çš„ ORMï¼‰
| Allows reuse of DB configuration and model definitions.ï¼ˆå…è®¸é‡ç”¨æ•°æ®åº“é…ç½®å’Œæ¨¡å‹å®šä¹‰ã€‚ï¼‰
| Adds another query language with its own quirks and syntax.ï¼ˆå¢åŠ äº†ä¸€ç§æŸ¥è¯¢è¯­è¨€ï¼ŒåŒæ—¶å¸¦æ¥äº†å®ƒçš„ç‰¹æ€§å’Œè¯­æ³•å¤æ‚æ€§ã€‚ï¼‰

| Use hand-rolled SQL to query your normal model tablesï¼ˆä½¿ç”¨æ‰‹å†™ SQL æŸ¥è¯¢æ­£å¸¸çš„æ¨¡å‹è¡¨ï¼‰
| Offers fine control over performance with a standard query syntax.ï¼ˆæä¾›äº†é€šè¿‡æ ‡å‡†æŸ¥è¯¢è¯­æ³•å¯¹æ€§èƒ½çš„ç²¾ç»†æ§åˆ¶ã€‚ï¼‰
| Changes to DB schema have to be made to your hand-rolled queries _and_ your
  ORM definitions. Highly normalized schemas may still have performance
  limitations.ï¼ˆå¯¹æ•°æ®åº“æ¨¡å¼çš„æ›´æ”¹éœ€è¦åŒæ—¶ä¿®æ”¹æ‰‹å†™ SQL æŸ¥è¯¢ _å’Œ_ ORM å®šä¹‰ã€‚é«˜åº¦è§„èŒƒåŒ–çš„æ¨¡å¼å¯èƒ½ä»ç„¶å­˜åœ¨æ€§èƒ½é™åˆ¶ã€‚ï¼‰

| Add some extra (denormalized) tables to your DB as a read modelï¼ˆå‘æ•°æ®åº“ä¸­æ·»åŠ ä¸€äº›é¢å¤–çš„ï¼ˆåè§„èŒƒåŒ–ï¼‰è¡¨ä½œä¸ºè¯»æ¨¡å‹ï¼‰
| A denormalized table can be much faster to query. If we update the
  normalized and denormalized ones in the same transaction, we will
  still have good guarantees of data consistencyï¼ˆåè§„èŒƒåŒ–çš„è¡¨æŸ¥è¯¢é€Ÿåº¦ä¼šå¿«å¾—å¤šã€‚å¦‚æœæˆ‘ä»¬åœ¨åŒä¸€ä¸ªäº‹åŠ¡ä¸­åŒæ—¶æ›´æ–°è§„èŒƒåŒ–è¡¨å’Œåè§„èŒƒåŒ–è¡¨ï¼Œä»ç„¶å¯ä»¥ä¿è¯è¾ƒå¥½çš„æ•°æ®ä¸€è‡´æ€§ã€‚ï¼‰
| It will slow down writes slightlyï¼ˆä¼šç¨å¾®é™ä½å†™å…¥é€Ÿåº¦ã€‚ï¼‰

| Create separate read stores with eventsï¼ˆä½¿ç”¨äº‹ä»¶åˆ›å»ºç‹¬ç«‹çš„è¯»å­˜å‚¨ï¼‰
| Read-only copies are easy to scale out. Views can be constructed when data
  changes so that queries are as simple as possible.ï¼ˆåªè¯»å‰¯æœ¬æ˜“äºæ¨ªå‘æ‰©å±•ã€‚è§†å›¾å¯ä»¥åœ¨æ•°æ®æ›´æ”¹æ—¶æ„å»ºï¼Œä»è€Œä½¿æŸ¥è¯¢å°½å¯èƒ½ç®€å•ã€‚ï¼‰
| Complex technique. Harry will be forever suspicious of your tastes and
  motives.ï¼ˆæŠ€æœ¯å¤æ‚æ€§è¾ƒé«˜ã€‚Harry ä¼šæ°¸è¿œå¯¹ä½ çš„å“å‘³å’ŒåŠ¨æœºä¿æŒæ€€ç–‘ã€‚ï¼‰
|===

// IDEA (EJ3) Might be useful to re-iterate what "full-blown" CQRS means vs simpler CQRS options.  I think
//      most blog posts describe CQRS in terms of the "full-blown" version, while
//      ignoring over the simpler version that is developed earlier in this chapter.
//
//      In my experience, many people react to CQRS with the response that
//      it's insane/too complex/too-hard and want to fall back to a CRUD hammer.
//

Often, your read operations will be acting on the same conceptual objects as your
write model, so using the ORM, adding some read methods to your repositories,
and using domain model classes for your read operations is _just fine_.

é€šå¸¸æƒ…å†µä¸‹ï¼Œä½ çš„è¯»æ“ä½œå°†ä½œç”¨äºä¸å†™æ¨¡å‹ç›¸åŒçš„æ¦‚å¿µæ€§å¯¹è±¡ï¼Œå› æ­¤ä½¿ç”¨ ORMã€åœ¨ä»“å‚¨ä¸­æ·»åŠ ä¸€äº›è¯»æ–¹æ³•ï¼Œä»¥åŠä½¿ç”¨é¢†åŸŸæ¨¡å‹ç±»è¿›è¡Œè¯»æ“ä½œæ˜¯ _å®Œå…¨æ²¡é—®é¢˜çš„_ã€‚

In our book example, the read operations act on quite different conceptual
entities to our domain model. The allocation service thinks in terms of
`Batches` for a single SKU, but users care about allocations for a whole order,
with multiple SKUs, so using the ORM ends up being a little awkward. We'd be
quite tempted to go with the raw-SQL view we showed right at the beginning of
the chapter.

åœ¨æˆ‘ä»¬çš„ä¹¦ä¸­ç¤ºä¾‹ä¸­ï¼Œè¯»æ“ä½œä½œç”¨çš„æ¦‚å¿µå®ä½“ä¸æˆ‘ä»¬çš„é¢†åŸŸæ¨¡å‹æˆªç„¶ä¸åŒã€‚åˆ†é…æœåŠ¡ä»¥å•ä¸ª SKU çš„ `Batches` ä¸ºå‡ºå‘ç‚¹ï¼Œ
è€Œç”¨æˆ·å…³å¿ƒçš„æ˜¯æ•´ä¸ªè®¢å•çš„åˆ†é…ï¼Œå…¶ä¸­åŒ…å«å¤šä¸ª SKUï¼Œå› æ­¤ä½¿ç”¨ ORM ä¼šæ˜¾å¾—æœ‰äº›åˆ«æ‰­ã€‚æˆ‘ä»¬ä¼šéå¸¸å€¾å‘äºé‡‡ç”¨æˆ‘ä»¬åœ¨æœ¬ç« å¼€å¤´å±•ç¤ºçš„åŸç”Ÿ SQL è§†å›¾ã€‚

On that note, let's sally forth into our final chapter.
((("command-query responsibility segregation (CQRS)", startref="ix_CQRS")))

è¯´åˆ°è¿™é‡Œï¼Œè®©æˆ‘ä»¬ç»§ç»­å‰è¿›ï¼Œè¿›å…¥æœ€åä¸€ç« å§ã€‚
